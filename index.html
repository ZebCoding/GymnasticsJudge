<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Gymnastics Judge AI</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 0; padding: 0; text-align: center; background: #111; color: white; }
    video { width: 100%; max-width: 480px; border: 2px solid #444; border-radius: 12px; margin: 10px; }
    canvas { display: none; }
    #debugCanvas { display: block; border: 2px solid #444; border-radius: 12px; margin: 10px; max-width: 480px; }
    .video-container { display: flex; justify-content: center; align-items: flex-start; flex-wrap: wrap; }
    .video-section { text-align: center; }
    .video-section h3 { margin: 5px 0; color: white; font-size: 1.1em; }
    .score { font-size: 2em; margin: 20px 0; }
    button { padding: 12px 20px; margin: 10px; font-size: 1em; border: none; border-radius: 8px; background: #007BFF; color: white; }
    button:hover { background: #0056b3; }
    button:disabled { background: #555; }
  </style>
  <!-- Load MediaPipe Pose -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/pose.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
</head>
<body>
  <h1>Gymnastics Judge AI</h1>
  <div class="video-container">
    <div class="video-section">
      <h3>Camera Feed</h3>
      <video id="camera" autoplay playsinline></video>
    </div>
    <div class="video-section">
      <h3>Pose Detection</h3>
      <canvas id="debugCanvas"></canvas>
    </div>
  </div>
  <canvas id="snapshot"></canvas>
  <div class="score">Score: <span id="score">10.0</span></div>
  <div id="poseStatus" style="color: #888; font-size: 0.9em; margin: 10px 0;">Pose: Not detecting</div>

  <button id="startRoutine">Ready for Routine</button>
  <button id="endRoutine" disabled>Manual End</button>
  <button id="viewDeductions" onclick="location.href='deductions.html'">View Deductions</button>
  <button id="clearLog">Clear Log</button>
  <button id="toggleDebug">Show Pose Debug</button>

  <script>
    const video = document.getElementById('camera');
    const canvas = document.getElementById('snapshot');
    const ctx = canvas.getContext('2d');
    const debugCanvas = document.getElementById('debugCanvas');
    const debugCtx = debugCanvas.getContext('2d');
    const scoreDisplay = document.getElementById('score');
    const poseStatus = document.getElementById('poseStatus');

    const startBtn = document.getElementById('startRoutine');
    const endBtn = document.getElementById('endRoutine');
    const clearLogBtn = document.getElementById('clearLog');
    const toggleDebugBtn = document.getElementById('toggleDebug');
    
    let showDebug = true; // Start with debug visible

    let score = 10.0;
    let deductions = [];
    let mediaStream;
    let mediaRecorder;
    let recordedChunks = [];
    let routineStarted = false;

    // Control repeated deductions: per-reason cooldown in milliseconds
    const DEDUCTION_COOLDOWN_MS = 1500;
    let lastDeductionAt = {}; // reason -> timestamp (performance.now())
    
    // Detection loop monitoring
    let lastDetectionTime = 0;
    let detectionLoopRunning = false;
    let poseFailureCount = 0;
    const MAX_POSE_FAILURES = 10;
    
    // Frame rate limiting to prevent freezing
    let lastFrameTime = 0;
    const TARGET_FPS = 15; // Limit to 15fps for better stability
    const FRAME_INTERVAL = 1000 / TARGET_FPS;
    
    // Gesture detection
    let waitingForSalute = false;
    let waitingForBow = false;
    let gestureHoldFrames = 0;
    const GESTURE_HOLD_REQUIRED = 30; // ~0.5 seconds at 60fps
    const SALUTE_ARM_ANGLE_THRESHOLD = 45; // arms up angle
    const BOW_TORSO_ANGLE_THRESHOLD = 30; // forward lean angle

    // Get camera and start pose detection immediately
    navigator.mediaDevices.getUserMedia({ video: true })
      .then(stream => { 
        mediaStream = stream; 
        video.srcObject = stream;
        console.log('Camera stream obtained');
        
        // Start pose detection when video is ready
        video.addEventListener('loadeddata', () => {
          console.log('Video loaded, dimensions:', video.videoWidth, 'x', video.videoHeight);
          // Wait a moment for video to stabilize
          setTimeout(() => {
            console.log('Starting pose detection...');
            detectPose();
          }, 1000);
        });
      })
      .catch(err => { 
        console.error('Camera error:', err);
        alert('Camera not available: ' + err); 
      });

    // Utility functions
    function calculateAngle(A, B, C) {
      const AB = {x: B.x - A.x, y: B.y - A.y};
      const CB = {x: B.x - C.x, y: B.y - C.y};
      const dot = AB.x * CB.x + AB.y * CB.y;
      const magAB = Math.sqrt(AB.x*AB.x + AB.y*AB.y);
      const magCB = Math.sqrt(CB.x*CB.x + CB.y*CB.y);
      
      // Prevent division by zero or invalid angles
      if (magAB === 0 || magCB === 0) {
        console.log('Warning: Zero magnitude in angle calculation');
        return 180; // Return straight line angle as default
      }
      
      const cosAngle = dot / (magAB * magCB);
      // Clamp to valid range for acos to prevent NaN
      const clampedCos = Math.max(-1, Math.min(1, cosAngle));
      const angle = Math.acos(clampedCos) * (180/Math.PI);
      
      // Validate result
      if (isNaN(angle)) {
        console.log('Warning: NaN angle calculated, returning 180°');
        return 180;
      }
      
      return angle;
    }

    function distance(A, B) {
      return Math.sqrt((A.x - B.x)**2 + (A.y - B.y)**2);
    }
    
    function detectSalute(landmarks) {
      // One-arm salute detection with visibility + multiple cues
      const nose = landmarks[0];
      const leftShoulder = landmarks[11], rightShoulder = landmarks[12];
      const leftElbow = landmarks[13], rightElbow = landmarks[14];
      const leftWrist = landmarks[15], rightWrist = landmarks[16];
      
      if (!nose || !leftShoulder || !rightShoulder || !leftElbow || !rightElbow || !leftWrist || !rightWrist) return false;
      
      // Helper to validate landmark confidence
      const visOK = (lm) => lm.visibility === undefined || lm.visibility >= 0.5;
      if (![nose, leftShoulder, rightShoulder, leftElbow, rightElbow, leftWrist, rightWrist].every(visOK)) {
        return false;
      }
      
      // Consider an arm raised if wrist and elbow are above shoulder (y smaller = higher)
      // and optionally wrist near head level to be robust to different body sizes
      const leftRaised = (leftWrist.y < leftShoulder.y - 0.08 && leftElbow.y < leftShoulder.y - 0.04) || (leftWrist.y < (nose.y + 0.05));
      const rightRaised = (rightWrist.y < rightShoulder.y - 0.08 && rightElbow.y < rightShoulder.y - 0.04) || (rightWrist.y < (nose.y + 0.05));
      
      // Accept salute when at least one arm is raised
      return leftRaised || rightRaised;
    }
    
    function drawPoseSkeleton(landmarks) {
      if (!landmarks) return;
      
      // Set canvas dimensions to match video (but independent sizing)
      const videoWidth = video.videoWidth || 640;
      const videoHeight = video.videoHeight || 480;
      const displayWidth = Math.min(480, videoWidth);
      const displayHeight = (displayWidth * videoHeight) / videoWidth;
      
      // Only resize if dimensions changed
      if (debugCanvas.width !== videoWidth || debugCanvas.height !== videoHeight) {
        debugCanvas.width = videoWidth;
        debugCanvas.height = videoHeight;
        debugCanvas.style.width = displayWidth + 'px';
        debugCanvas.style.height = displayHeight + 'px';
        console.log('Canvas resized to:', videoWidth, 'x', videoHeight, 'display:', displayWidth, 'x', displayHeight);
      }
      
      // Clear previous frame
      debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
      
      const w = debugCanvas.width;
      const h = debugCanvas.height;
      
      // Draw landmarks as dots (more forgiving visibility check)
      debugCtx.fillStyle = '#00ff00';
      landmarks.forEach((landmark, i) => {
        if (landmark && (landmark.visibility === undefined || landmark.visibility > 0.3)) {
          const x = landmark.x * w;
          const y = landmark.y * h;
          debugCtx.beginPath();
          debugCtx.arc(x, y, 4, 0, 2 * Math.PI);
          debugCtx.fill();
          
          // Label key points
          if ([0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28].includes(i)) {
            debugCtx.fillStyle = '#ffffff';
            debugCtx.font = '12px Arial';
            debugCtx.fillText(i, x + 6, y - 6);
            debugCtx.fillStyle = '#00ff00';
          }
        }
      });
      
      // Draw skeleton connections
      debugCtx.strokeStyle = '#ff0000';
      debugCtx.lineWidth = 2;
      
      // Define body connections (MediaPipe pose connections)
      const connections = [
        [11, 12], [11, 13], [13, 15], [12, 14], [14, 16], // Arms
        [11, 23], [12, 24], [23, 24], // Torso
        [23, 25], [25, 27], [24, 26], [26, 28], // Legs
        [0, 1], [1, 2], [2, 3], [3, 7], // Head (simplified)
      ];
      
      connections.forEach(([a, b]) => {
        const pointA = landmarks[a];
        const pointB = landmarks[b];
        if (pointA && pointB && pointA.visibility > 0.5 && pointB.visibility > 0.5) {
          debugCtx.beginPath();
          debugCtx.moveTo(pointA.x * w, pointA.y * h);
          debugCtx.lineTo(pointB.x * w, pointB.y * h);
          debugCtx.stroke();
        }
      });
    }
    
    function detectBow(landmarks) {
      // Check if person is bowing (head lower than shoulders, torso leaning forward)
      const nose = landmarks[0];
      const leftShoulder = landmarks[11], rightShoulder = landmarks[12];
      const leftHip = landmarks[23], rightHip = landmarks[24];
      
      if (!nose || !leftShoulder || !rightShoulder || !leftHip || !rightHip) return false;
      
      // Calculate average shoulder and hip positions
      const shoulderY = (leftShoulder.y + rightShoulder.y) / 2;
      const hipY = (leftHip.y + rightHip.y) / 2;
      
      // Bow detected if nose is below shoulder level and torso is leaning
      const headLowered = nose.y > shoulderY + 0.05;
      const torsoLeaning = shoulderY > hipY - 0.15; // shoulders closer to hips indicates forward lean
      
      return headLowered && torsoLeaning;
    }

    // Setup MediaPipe Pose with error handling
    let pose;
    try {
      console.log('Initializing MediaPipe Pose...');
      pose = new Pose({locateFile: (file) => {
        const url = `https://cdn.jsdelivr.net/npm/@mediapipe/pose@0.5/${file}`;
        console.log('Loading MediaPipe file:', url);
        return url;
      }});
      pose.setOptions({
        modelComplexity: 1, 
        smoothLandmarks: true, 
        enableSegmentation: false,
        minDetectionConfidence: 0.5,
        minTrackingConfidence: 0.5
      });
      pose.onResults(onResults);
      console.log('MediaPipe Pose initialized successfully');
    } catch (error) {
      console.error('Failed to initialize MediaPipe Pose:', error);
      alert('Failed to load pose detection. Please refresh the page.');
    }

    async function detectPose() {
      const now = performance.now();
      
      // Frame rate limiting to prevent freezing
      if (now - lastFrameTime < FRAME_INTERVAL) {
        requestAnimationFrame(detectPose);
        return;
      }
      lastFrameTime = now;
      
      // Always run pose detection (not just during routine)
      detectionLoopRunning = true;
      lastDetectionTime = now;
      
      try {
        if (video.readyState >= 2 && video.videoWidth > 0) { // Video has data and dimensions
          await pose.send({image: video});
          poseFailureCount = 0;
        }
      } catch (error) {
        console.error('Pose detection error:', error);
        poseFailureCount++;
        
        if (poseFailureCount >= MAX_POSE_FAILURES) {
          console.log('Too many pose detection failures, will retry');
          poseFailureCount = 0; // Reset and try again
        }
      }
      
      requestAnimationFrame(detectPose);
    }

    function onResults(results) {
      // Add detailed debugging
      console.log('onResults called, pose landmarks:', !!results.poseLandmarks);
      
      if (!results.poseLandmarks) {
        console.log('No pose landmarks detected - check lighting and body visibility');
        poseStatus.textContent = 'Pose: Not detected - check lighting';
        poseStatus.style.color = '#888';
        // Clear debug canvas when no pose detected
        if (showDebug) {
          debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
        }
        return;
      } else {
        console.log('Pose landmarks detected! Count:', results.poseLandmarks.length);
      }

      const landmarks = results.poseLandmarks;
      
      // Always draw debug skeleton first (regardless of confidence)
      if (showDebug) {
        drawPoseSkeleton(landmarks);
      } else {
        debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
      }

      // Map keypoints
      const leftHip = landmarks[23], rightHip = landmarks[24];
      const leftKnee = landmarks[25], rightKnee = landmarks[26];
      const leftAnkle = landmarks[27], rightAnkle = landmarks[28];

      // Check if all required landmarks are visible (confidence > 0.5)
      const requiredLandmarks = [leftHip, rightHip, leftKnee, rightKnee, leftAnkle, rightAnkle];
      if (requiredLandmarks.some(landmark => !landmark || landmark.visibility < 0.5)) {
        console.log('Some required landmarks not visible or low confidence');
        poseStatus.textContent = 'Pose: Low confidence';
        poseStatus.style.color = '#ff9800';
        return;
      }

      // Good pose detection
      poseStatus.textContent = 'Pose: Tracking ✓';
      poseStatus.style.color = '#4caf50';
      
      // Gesture detection for auto start/stop
      if (waitingForSalute && !routineStarted) {
        // Debug wrist/shoulder positions occasionally
        if (Math.random() < 0.05) {
          const ls = landmarks[11], rs = landmarks[12], lw = landmarks[15], rw = landmarks[16];
          console.log(`Salute debug - LW:${lw?.y?.toFixed(3)} LS:${ls?.y?.toFixed(3)} RW:${rw?.y?.toFixed(3)} RS:${rs?.y?.toFixed(3)}`);
        }
        const isSaluting = detectSalute(landmarks);
        if (isSaluting) {
          gestureHoldFrames++;
          poseStatus.textContent = `Salute detected… ${Math.round(100 * gestureHoldFrames / GESTURE_HOLD_REQUIRED)}%`;
          poseStatus.style.color = '#4caf50';
          console.log(`Salute detected, holding for ${gestureHoldFrames}/${GESTURE_HOLD_REQUIRED} frames`);
          if (gestureHoldFrames >= GESTURE_HOLD_REQUIRED) {
            console.log('Salute confirmed - starting routine!');
            startRoutineAutomatically();
          }
        } else {
          gestureHoldFrames = 0;
          poseStatus.textContent = 'Ready - Waiting for Salute (raise one arm)';
          poseStatus.style.color = '#ff9800';
        }
      } else if (waitingForBow && routineStarted) {
        const isBowing = detectBow(landmarks);
        if (isBowing) {
          gestureHoldFrames++;
          console.log(`Bow detected, holding for ${gestureHoldFrames}/${GESTURE_HOLD_REQUIRED} frames`);
          if (gestureHoldFrames >= GESTURE_HOLD_REQUIRED) {
            console.log('Bow confirmed - ending routine!');
            endRoutineAutomatically();
          }
        } else {
          gestureHoldFrames = 0;
        }
      }

      // Knee angles
      const leftKneeAngle = calculateAngle(leftHip, leftKnee, leftAnkle);
      const rightKneeAngle = calculateAngle(rightHip, rightKnee, rightAnkle);
      const kneeThreshold = 160; // More sensitive - was 170

      // Debug measurements every 60 frames (~1 second at 60fps)
      if (Math.random() < 0.016) {
        console.log(`Measurements - Knee angles L:${leftKneeAngle.toFixed(1)}° R:${rightKneeAngle.toFixed(1)}°`);
        console.log(`Distances - Hips:${hipDistance.toFixed(3)} Ankles:${ankleDist.toFixed(3)} Knees:${kneeDist.toFixed(3)}`);
        console.log(`Ratios - Ankle/Hip:${(ankleDist/hipDistance).toFixed(2)} Knee/Hip:${(kneeDist/hipDistance).toFixed(2)}`);
        console.log(`Cooldowns - Left leg: ${((performance.now() - (lastDeductionAt['Left leg bent'] || 0))/1000).toFixed(1)}s ago, Right leg: ${((performance.now() - (lastDeductionAt['Right leg bent'] || 0))/1000).toFixed(1)}s ago`);
      }

      // Body width measurements
      const hipDistance = distance(leftHip, rightHip);
      const ankleDist = distance(leftAnkle, rightAnkle);
      const kneeDist = distance(leftKnee, rightKnee);
      
      // More sensitive legs apart detection - multiple methods
      const maxAnkleDistFactor = 1.3; // was 1.5 - more strict
      const maxKneeDistFactor = 1.4;  // knee distance shouldn't exceed this either
      
      // Also check absolute distance (for very wide stances)
      const maxAbsoluteAnkleDist = 0.3; // normalized coordinate distance

      // Check deductions with debugging - ONLY during routine
      if (routineStarted) {
        if (leftKneeAngle < kneeThreshold) {
          console.log(`Left leg bent detected: ${leftKneeAngle.toFixed(1)}° < ${kneeThreshold}°`);
          addDeduction("Left leg bent");
        } else if (leftKneeAngle < kneeThreshold + 5) {
          // Log near-misses to see if angles are fluctuating around threshold
          console.log(`Left leg close to bent: ${leftKneeAngle.toFixed(1)}° (threshold: ${kneeThreshold}°)`);
        }
        
        if (rightKneeAngle < kneeThreshold) {
          console.log(`Right leg bent detected: ${rightKneeAngle.toFixed(1)}° < ${kneeThreshold}°`);
          addDeduction("Right leg bent");
        } else if (rightKneeAngle < kneeThreshold + 5) {
          console.log(`Right leg close to bent: ${rightKneeAngle.toFixed(1)}° (threshold: ${kneeThreshold}°)`);
        }
      }
      // Multiple checks for legs too far apart - ONLY during routine
      if (routineStarted) {
        const ankleRatio = ankleDist / hipDistance;
        const kneeRatio = kneeDist / hipDistance;
        
        if (ankleRatio > maxAnkleDistFactor) {
          console.log(`Legs apart (ankle ratio): ${ankleRatio.toFixed(2)} > ${maxAnkleDistFactor}`);
          addDeduction("Legs too far apart");
        } else if (kneeRatio > maxKneeDistFactor) {
          console.log(`Legs apart (knee ratio): ${kneeRatio.toFixed(2)} > ${maxKneeDistFactor}`);
          addDeduction("Legs too far apart");
        } else if (ankleDist > maxAbsoluteAnkleDist) {
          console.log(`Legs apart (absolute): ${ankleDist.toFixed(3)} > ${maxAbsoluteAnkleDist}`);
          addDeduction("Legs too far apart");
        }
      }
    }

    function addDeduction(reason) {
      // Allow repeated deductions for the same reason after a short cooldown
      const now = performance.now();
      const lastTime = lastDeductionAt[reason] || 0;
      if (now - lastTime < DEDUCTION_COOLDOWN_MS) {
        console.log(`Deduction "${reason}" blocked by cooldown (${((now - lastTime)/1000).toFixed(1)}s ago)`);
        return;
      }
      lastDeductionAt[reason] = now;

      score = Math.max(5.0, score - 0.2);
      console.log(`Deduction applied: "${reason}" - New score: ${score.toFixed(1)}`);

      // Snapshot
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = canvas.toDataURL('image/png');

      const event = {
        time: new Date().toLocaleTimeString(),
        reason: reason,
        deduction: 0.2,
        remaining: score.toFixed(1),
        snapshot: imageData
      };
      deductions.push(event);
      scoreDisplay.textContent = score.toFixed(1);
      localStorage.setItem('deductionsLog', JSON.stringify(deductions));
    }
    
    function startRoutineAutomatically() {
      if (!mediaStream) return;
      
      routineStarted = true;
      waitingForSalute = false;
      waitingForBow = true;
      gestureHoldFrames = 0;
      
      startBtn.disabled = true;
      endBtn.disabled = false;
      
      // Reset score & log
      score = 10.0;
      deductions = [];
      lastDeductionAt = {};
      scoreDisplay.textContent = score.toFixed(1);
      localStorage.removeItem('deductionsLog');
      
      // Setup MediaRecorder
      mediaRecorder = new MediaRecorder(mediaStream, { mimeType: "video/webm" });
      mediaRecorder.ondataavailable = e => { if (e.data.size > 0) recordedChunks.push(e.data); };
      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: "video/webm" });
        const url = URL.createObjectURL(blob);
        const a = document.createElement("a");
        a.href = url;
        a.download = `routine_${Date.now()}.webm`;
        a.click();
        URL.revokeObjectURL(url);
        recordedChunks = [];
      };
      mediaRecorder.start();
      
      poseStatus.textContent = 'Routine Started - Tracking Performance';
      poseStatus.style.color = '#ff9800';
    }
    
    function endRoutineAutomatically() {
      if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
      routineStarted = false;
      waitingForBow = false;
      waitingForSalute = false;
      gestureHoldFrames = 0;
      
      startBtn.disabled = false;
      startBtn.textContent = 'Ready for Routine';
      endBtn.disabled = true;
      
      poseStatus.textContent = 'Routine Complete - Ready for Next';
      poseStatus.style.color = '#4caf50';
      
      alert(`Routine complete! Final Score: ${score.toFixed(1)}`);
    }

    // Start routine - now activates gesture detection mode
    startBtn.addEventListener('click', () => {
      if (!mediaStream) return alert("Camera not ready yet");

      // Enable gesture detection mode
      waitingForSalute = true;
      waitingForBow = false;
      gestureHoldFrames = 0;
      
      startBtn.textContent = 'Waiting for Salute...';
      startBtn.disabled = true;
      
      poseStatus.textContent = 'Ready - Waiting for Salute';
      poseStatus.style.color = '#ff9800';
      
      console.log('Gesture detection activated - raise one arm to salute and start routine');
      // Pose detection is already running continuously
    });

    // End routine
    endBtn.addEventListener('click', () => {
      if (mediaRecorder && mediaRecorder.state === "recording") mediaRecorder.stop();
      routineStarted = false;
      startBtn.disabled = false;
      endBtn.disabled = true;
      alert("Routine ended. Video saved. Ready for next routine.");
    });

    // Clear log
    clearLogBtn.addEventListener("click", () => {
      deductions = [];
      score = 10.0;
      scoreDisplay.textContent = score.toFixed(1);
      localStorage.removeItem('deductionsLog');
      alert("Log cleared, score reset.");
    });
    
    // Toggle debug overlay
    toggleDebugBtn.addEventListener('click', () => {
      showDebug = !showDebug;
      toggleDebugBtn.textContent = showDebug ? 'Hide Pose Debug' : 'Show Pose Debug';
      if (!showDebug) {
        debugCtx.clearRect(0, 0, debugCanvas.width, debugCanvas.height);
      }
    });
  </script>
</body>
</html>
